{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T20:34:18.277938Z",
     "iopub.status.busy": "2022-12-26T20:34:18.277559Z",
     "iopub.status.idle": "2022-12-26T20:34:29.311210Z",
     "shell.execute_reply": "2022-12-26T20:34:29.310286Z",
     "shell.execute_reply.started": "2022-12-26T20:34:18.277899Z"
    },
    "id": "0qPjmWP1dfoA",
    "outputId": "1fe72046-9212-40fe-e24f-0831625bbc12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting adversarial-robustness-toolbox\n",
      "  Downloading adversarial_robustness_toolbox-1.13.0-py3-none-any.whl (1.4 MB)\n",
      "     |████████████████████████████████| 1.4 MB 2.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (59.5.0)\n",
      "Requirement already satisfied: scikit-learn<1.2.0,>=0.22.2 in /opt/conda/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (1.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (1.20.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (1.7.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (1.1.0)\n",
      "Installing collected packages: adversarial-robustness-toolbox\n",
      "Successfully installed adversarial-robustness-toolbox-1.13.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install adversarial-robustness-toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T20:34:29.315167Z",
     "iopub.status.busy": "2022-12-26T20:34:29.314540Z",
     "iopub.status.idle": "2022-12-26T20:34:29.324488Z",
     "shell.execute_reply": "2022-12-26T20:34:29.323668Z",
     "shell.execute_reply.started": "2022-12-26T20:34:29.315134Z"
    },
    "id": "dnRtCysGfTWX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained Models \n",
    "# from keras.applications.densenet import DenseNet169, preprocess_input as densenet_preprocess_input \n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Load ART dependencies:\n",
    "from art.estimators.classification import KerasClassifier\n",
    "\n",
    "# Attacks \n",
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.attacks.evasion import BasicIterativeMethod \n",
    "from art.attacks.evasion import CarliniL2Method\n",
    "from art.attacks.evasion import DeepFool\n",
    "from art.attacks.evasion import FrameSaliencyAttack\n",
    "from art.attacks.evasion import HopSkipJump\n",
    "\n",
    "# Defenses \n",
    "from art.defences.preprocessor import SpatialSmoothing\n",
    "from art.defences.preprocessor import FeatureSqueezing\n",
    "from art.defences.preprocessor import GaussianAugmentation\n",
    "from art.defences.preprocessor import LabelSmoothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T20:34:40.683462Z",
     "iopub.status.busy": "2022-12-26T20:34:40.683149Z",
     "iopub.status.idle": "2022-12-26T20:34:40.689092Z",
     "shell.execute_reply": "2022-12-26T20:34:40.688267Z",
     "shell.execute_reply.started": "2022-12-26T20:34:40.683428Z"
    },
    "id": "9H5YYpysfWUn"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "if tf.executing_eagerly():\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "tf.compat.v1.experimental.output_all_intermediates(True) \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T09:05:35.332895Z",
     "iopub.status.busy": "2022-12-26T09:05:35.332476Z",
     "iopub.status.idle": "2022-12-26T09:05:35.338953Z",
     "shell.execute_reply": "2022-12-26T09:05:35.337982Z",
     "shell.execute_reply.started": "2022-12-26T09:05:35.332824Z"
    },
    "id": "Bcxs3tH_f0mm"
   },
   "outputs": [],
   "source": [
    "from art.preprocessing.preprocessing import Preprocessor\n",
    "\n",
    "class VGG16Preprocessor(Preprocessor):\n",
    "\n",
    "    def __call__(self, x, y=None):\n",
    "        return preprocess_input(x.copy()), y\n",
    "\n",
    "    def estimate_gradient(self, x, gradient):\n",
    "        return gradient[..., ::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CIFAR Section**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T20:34:53.200042Z",
     "iopub.status.busy": "2022-12-26T20:34:53.199723Z",
     "iopub.status.idle": "2022-12-26T20:34:53.531304Z",
     "shell.execute_reply": "2022-12-26T20:34:53.530477Z",
     "shell.execute_reply.started": "2022-12-26T20:34:53.200007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.6.2\n"
     ]
    }
   ],
   "source": [
    "# Importing required modules\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import LambdaCallback \n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.datasets import mnist, cifar10\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f'Tensorflow version: {tf.__version__}')\n",
    "# tf.compat.v1.enable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T20:34:57.144649Z",
     "iopub.status.busy": "2022-12-26T20:34:57.144061Z",
     "iopub.status.idle": "2022-12-26T20:34:57.153341Z",
     "shell.execute_reply": "2022-12-26T20:34:57.152347Z",
     "shell.execute_reply.started": "2022-12-26T20:34:57.144611Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def print_shapes(x_train, x_test, y_train, y_test):\n",
    "  print(f\"x_train: {x_train.shape}\\n\"\\\n",
    "      f\"x_test: {x_test.shape}\\n\"\\\n",
    "      f\"y_train: {y_train.shape}\\n\"\\\n",
    "      f\"y_test: {y_test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T20:34:59.583414Z",
     "iopub.status.busy": "2022-12-26T20:34:59.582792Z",
     "iopub.status.idle": "2022-12-26T20:35:03.442799Z",
     "shell.execute_reply": "2022-12-26T20:35:03.441918Z",
     "shell.execute_reply.started": "2022-12-26T20:34:59.583376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 2s 0us/step\n",
      "170508288/170498071 [==============================] - 2s 0us/step\n",
      "x_train: (50000, 32, 32, 3)\n",
      "x_test: (10000, 32, 32, 3)\n",
      "y_train: (50000, 1)\n",
      "y_test: (10000, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loading the dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print_shapes(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T20:35:05.684610Z",
     "iopub.status.busy": "2022-12-26T20:35:05.683957Z",
     "iopub.status.idle": "2022-12-26T20:35:06.255960Z",
     "shell.execute_reply": "2022-12-26T20:35:06.255189Z",
     "shell.execute_reply.started": "2022-12-26T20:35:05.684566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (50000, 32, 32, 3)\n",
      "x_test: (10000, 32, 32, 3)\n",
      "y_train: (50000, 10)\n",
      "y_test: (10000, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing images and labels\n",
    "height, width, channels = 32, 32, 3\n",
    "nb_classes = 10 \n",
    "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog',\n",
    "               'horse', 'ship', 'truck']\n",
    "\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train = x_train.reshape((-1, height, width, channels))\n",
    "x_test = x_test.reshape((-1, height, width, channels))\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "print_shapes(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T20:35:12.390429Z",
     "iopub.status.busy": "2022-12-26T20:35:12.390133Z",
     "iopub.status.idle": "2022-12-26T20:35:12.736939Z",
     "shell.execute_reply": "2022-12-26T20:35:12.736066Z",
     "shell.execute_reply.started": "2022-12-26T20:35:12.390398Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "from keras.layers.core import Lambda\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "\n",
    "import cv2\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "arryWeights_last = []\n",
    "\n",
    "class cifar10vgg:\n",
    "    arryWeights_last = []\n",
    "    for i in range (512):\n",
    "        arryWeights_last.append (i)\n",
    "\n",
    "    for i in range (512):\n",
    "        arryWeights_last[i] = 1\n",
    "\n",
    "    def custom_layer_last(self, tensor):\n",
    "        # for i in range(64):\n",
    "        #   if i>=1:\n",
    "        #     #tensor[i]*=arryWeights[i]\n",
    "        #     tensor[i] * arryWeights[i]\n",
    "        return tensor * self.arryWeights_last\n",
    "\n",
    "    def __init__(self,train=False):\n",
    "        #Sequential.__init__ (self)\n",
    "        self.num_classes = 10\n",
    "        self.weight_decay = 0.0005\n",
    "        self.x_shape = [32,32,3]\n",
    "        self.model = self.build_model()\n",
    "        if train:\n",
    "             self.model = self.train(self.model)\n",
    "        else:\n",
    "            self.model.load_weights('../input/vgg-cifar-wights/cifar10vgg.h5')\n",
    "\n",
    "    def build_model(self):\n",
    "        # Build the network of vgg for 10 classes with massive dropout and weight decay as described in the paper.\n",
    "        model = Sequential()\n",
    "        weight_decay = self.weight_decay\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                         input_shape=self.x_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Lambda(self.custom_layer_last, name=\"lambda_layer_last\"))\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(self.num_classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        #model.summary()\n",
    "        return model\n",
    "\n",
    "\n",
    "    def normalize(self,X_train,X_test):\n",
    "        #this function normalize inputs for zero mean and unit variance\n",
    "        # it is used when training a model.\n",
    "        # Input: training set and test set\n",
    "        # Output: normalized training set and test set according to the trianing set statistics.\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7)\n",
    "        return X_train, X_test\n",
    "\n",
    "    def normalize_production(self,x):\n",
    "        #this function is used to normalize instances in production according to saved training set statistics\n",
    "        # Input: X - a training set\n",
    "        # Output X - a normalized training set according to normalization constants.\n",
    "\n",
    "        #these values produced during first training and are general for the standard cifar10 training set normalization\n",
    "        mean = 120.707\n",
    "        std = 64.15\n",
    "        return (x-mean)/(std+1e-7)\n",
    "\n",
    "    def predict(self,x,normalize=True,batch_size=50):\n",
    "        if normalize:\n",
    "            x = self.normalize_production(x)\n",
    "        return self.model.predict(x,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T20:35:32.356263Z",
     "iopub.status.busy": "2022-12-26T20:35:32.355969Z",
     "iopub.status.idle": "2022-12-26T20:35:42.917551Z",
     "shell.execute_reply": "2022-12-26T20:35:42.916716Z",
     "shell.execute_reply.started": "2022-12-26T20:35:32.356227Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-26 20:35:32.582228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 20:35:32.583380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 20:35:32.584452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 20:35:32.585189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 20:35:32.586002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 20:35:32.586831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 20:35:34.446823: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 20:35:34.714377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 20:35:34.715707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 20:35:34.716840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 20:35:34.717894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 20:35:34.718961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 20:35:34.719991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 20:35:41.934129: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 20:35:41.935576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 20:35:41.936734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 20:35:41.937712: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 20:35:41.938743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 20:35:41.939674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13309 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2022-12-26 20:35:41.942865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-26 20:35:41.943881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13309 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# from keras.applications import VGG16\n",
    "# from vis.utils import utils\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "from keras import activations\n",
    "from keras.models import Sequential, Model, load_model\n",
    "\n",
    "    \n",
    "# Build the VGG16 network with ImageNet weights\n",
    "model = cifar10vgg ()\n",
    "# model = utils.apply_modifications(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T20:35:49.561582Z",
     "iopub.status.busy": "2022-12-26T20:35:49.561302Z",
     "iopub.status.idle": "2022-12-26T20:35:50.595743Z",
     "shell.execute_reply": "2022-12-26T20:35:50.594688Z",
     "shell.execute_reply.started": "2022-12-26T20:35:49.561550Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "from keras.layers.core import Lambda\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "\n",
    "import cv2\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "# predicted_x = model.predict (x_test)\n",
    "# residuals = np.argmax (predicted_x, 1) != np.argmax (y_test, 1)\n",
    "\n",
    "# loss = sum (residuals) / len (residuals)\n",
    "# print (\"the validation 0/1 loss is: \", loss)\n",
    "# # print (\"accu is: \", 1- loss)\n",
    "# orig_acc = 1 - loss\n",
    "# print (\"origin accu is: \", 1- loss)\n",
    "# original_loss = model.evaluate(x_test, y_test, verbose=0)\n",
    "# print('original model loss:', original_loss, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CIFAR perturbation section**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T20:36:01.931247Z",
     "iopub.status.busy": "2022-12-26T20:36:01.930952Z",
     "iopub.status.idle": "2022-12-26T20:36:01.937774Z",
     "shell.execute_reply": "2022-12-26T20:36:01.937085Z",
     "shell.execute_reply.started": "2022-12-26T20:36:01.931207Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pretrained Models \n",
    "# from keras.applications.densenet import DenseNet169, preprocess_input as densenet_preprocess_input \n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Load ART dependencies:\n",
    "from art.estimators.classification import KerasClassifier\n",
    "\n",
    "# Attacks \n",
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.attacks.evasion import BasicIterativeMethod \n",
    "from art.attacks.evasion import CarliniL2Method\n",
    "from art.attacks.evasion import DeepFool\n",
    "from art.attacks.evasion import FrameSaliencyAttack\n",
    "from art.attacks.evasion import HopSkipJump\n",
    "\n",
    "# Defenses \n",
    "from art.defences.preprocessor import SpatialSmoothing\n",
    "from art.defences.preprocessor import FeatureSqueezing\n",
    "from art.defences.preprocessor import GaussianAugmentation\n",
    "from art.defences.preprocessor import LabelSmoothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T20:36:06.335410Z",
     "iopub.status.busy": "2022-12-26T20:36:06.335073Z",
     "iopub.status.idle": "2022-12-26T20:36:06.340638Z",
     "shell.execute_reply": "2022-12-26T20:36:06.339767Z",
     "shell.execute_reply.started": "2022-12-26T20:36:06.335374Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "if tf.executing_eagerly():\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "tf.compat.v1.experimental.output_all_intermediates(True) \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T20:36:11.896629Z",
     "iopub.status.busy": "2022-12-26T20:36:11.896307Z",
     "iopub.status.idle": "2022-12-26T20:36:13.737969Z",
     "shell.execute_reply": "2022-12-26T20:36:13.737244Z",
     "shell.execute_reply.started": "2022-12-26T20:36:11.896597Z"
    }
   },
   "outputs": [],
   "source": [
    "from art.estimators.classification import KerasClassifier\n",
    "import numpy as np\n",
    "# from art.attacks.evasion import FastGradientMethod\n",
    "from art.attacks.evasion import auto_projected_gradient_descent\n",
    "\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from sklearn.metrics import accuracy_score as accuracy \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "# model1 = keras.models.load_model(\"gdrive/MyDrive/CIFAR10.h5\")\n",
    "\n",
    "\n",
    "from art.preprocessing.preprocessing import Preprocessor\n",
    "\n",
    "class VGG16Preprocessor(Preprocessor):\n",
    "\n",
    "    def __call__(self, x, y=None):\n",
    "        return preprocess_input(x.copy()), y\n",
    "\n",
    "    def estimate_gradient(self, x, gradient):\n",
    "        return gradient[..., ::-1]\n",
    "    \n",
    "\n",
    "# # Create the ART preprocessor and classifier wrapper:\n",
    "preprocessor = VGG16Preprocessor()\n",
    "# classifier = KerasClassifier(clip_values=(0, 255), model=model, preprocessing=preprocessor)\n",
    "classifier = KerasClassifier(clip_values=(0, 255), model=model.model, preprocessing=preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FGSM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-25T19:35:37.947044Z",
     "iopub.status.busy": "2022-12-25T19:35:37.946737Z",
     "iopub.status.idle": "2022-12-25T19:35:39.030012Z",
     "shell.execute_reply": "2022-12-25T19:35:39.028980Z",
     "shell.execute_reply.started": "2022-12-25T19:35:37.947011Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17/1469977143.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mattack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastGradientMethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# it should be from 16 to 96 according to ADVERSARIAL VISUAL ROBUSTNESS BY CAUSAL INTERVENTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mx_test_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score as accuracy \n",
    "from keras.utils.np_utils import to_categorical \n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# x_train = x_train / 255\n",
    "# x_test = x_test / 255\n",
    "\n",
    "# x_train = x_train.reshape((-1, height, width, channels))\n",
    "# x_test = x_test.reshape((-1, height, width, channels))\n",
    "\n",
    "# y_train = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "# y_test = tf.keras.utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "\n",
    "attack = FastGradientMethod(estimator=classifier, eps=24) # it should be from 16 to 96 according to ADVERSARIAL VISUAL ROBUSTNESS BY CAUSAL INTERVENTION\n",
    "x_test_adv = attack.generate(x=x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PGD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import ProjectedGradientDescent \n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "attack = ProjectedGradientDescent(classifier, targeted=False, max_iter=10, eps_step=1, eps=24)  \n",
    "# attack = BasicIterativeMethod(classifier, eps=1.0, eps_step=0.1, batch_size=128, verbose=False)\n",
    "x_test_adv = attack.generate(x=x_test)\n",
    "predictions = classifier.predict(x_test_adv)\n",
    "perturbation = np.mean(np.abs((x_test_adv - x_test)))\n",
    "print(\"Eps value=0.1\")\n",
    "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy(np.argmax(predictions, axis=1),y_test) * 100))\n",
    "print('Average perturbation: {:4.2f}'.format(perturbation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T15:10:06.542698Z",
     "iopub.status.busy": "2022-12-23T15:10:06.542426Z",
     "iopub.status.idle": "2022-12-23T15:10:06.546169Z",
     "shell.execute_reply": "2022-12-23T15:10:06.545372Z",
     "shell.execute_reply.started": "2022-12-23T15:10:06.542667Z"
    }
   },
   "outputs": [],
   "source": [
    "# x_test_adv[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BIM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import BasicIterativeMethod \n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "attack = BasicIterativeMethod(estimator=classifier, targeted=False, eps=24)\n",
    "# attack = BasicIterativeMethod(classifier, eps=1.0, eps_step=0.1, batch_size=128, verbose=False)\n",
    "x_test_adv = attack.generate(x=x_test)\n",
    "predictions = classifier.predict(x_test_adv)\n",
    "perturbation = np.mean(np.abs((x_test_adv - x_test)))\n",
    "print(\"Eps value=0.1\")\n",
    "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy(np.argmax(predictions, axis=1),y_test) * 100))\n",
    "print('Average perturbation: {:4.2f}'.format(perturbation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T20:42:20.471164Z",
     "iopub.status.busy": "2022-12-26T20:42:20.470887Z",
     "iopub.status.idle": "2022-12-26T20:42:20.478233Z",
     "shell.execute_reply": "2022-12-26T20:42:20.477385Z",
     "shell.execute_reply.started": "2022-12-26T20:42:20.471134Z"
    }
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "for i in range(0, 10):\n",
    "# for i in range(1000):\n",
    "    if not os.path.exists('PGD/classes/' + str(i) +'/'):\n",
    "        os.makedirs('PGD/classes/' + str(i) +'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T22:12:13.342787Z",
     "iopub.status.busy": "2022-12-26T22:12:13.342227Z",
     "iopub.status.idle": "2022-12-26T22:12:14.161419Z",
     "shell.execute_reply": "2022-12-26T22:12:14.160537Z",
     "shell.execute_reply.started": "2022-12-26T22:12:13.342747Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save PGD test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy\n",
    "import re \n",
    "\n",
    "for i in range (len (x_test_adv)):\n",
    "    print((y_test[i]))\n",
    "    clas = subStr = str(y_test[i]).split('[')[1].split(']')[0]\n",
    "    print(clas)\n",
    "    dst = \"PGD/classes/\" + clas +'/'+ str(i) + '.png' # replace PGD/FGSM/BIM\n",
    "    print(\"dist: \", dst)\n",
    "#         Path(folder_Copy+j+\"/\").mkdir(parents=True, exist_ok=True)\n",
    "    img_numpy = np.array(x_test_adv[i])\n",
    "    PIL_image = Image.fromarray(img_numpy.astype('uint8'), 'RGB')\n",
    "    PIL_image.save(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r file.zip './PGD'\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-26T22:13:18.763979Z",
     "iopub.status.busy": "2022-12-26T22:13:18.763650Z",
     "iopub.status.idle": "2022-12-26T22:13:18.770400Z",
     "shell.execute_reply": "2022-12-26T22:13:18.769559Z",
     "shell.execute_reply.started": "2022-12-26T22:13:18.763928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='file.zip' target='_blank'>file.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/file.zip"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(r'file.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Lambda\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, MaxPool2D \n",
    "from keras.layers import Lambda\n",
    "import time\n",
    "from keras.utils.np_utils import to_categorical \n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input, decode_predictions\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "indices_Of_Pert_Images =[]\n",
    "k=0\n",
    "for i in range (len (x_test)):\n",
    "    probs = model.predict (x_test[np.newaxis, i])\n",
    "\n",
    "    prediction = probs.argmax (axis=1)\n",
    "    probOrig = probs.max()\n",
    "\n",
    "    probs_pert = model.predict(x_test_adv[np.newaxis, i])\n",
    "\n",
    "    prediction_pert = probs_pert.argmax (axis=1)\n",
    "    pro_pert = probs_pert.max ()\n",
    "    \n",
    "    if prediction[0]== np.argmax (y_test[i]) and prediction_pert[0]!= np.argmax (y_test[i]) :\n",
    "        k+=1\n",
    "        print(np.argmax (y_test[i]) , \"is misclaissified as \", prediction_pert[0])  \n",
    "        print('not correctly classified:', k)\n",
    "#       print('current accuracy:', k/len(x_test))\n",
    "        print('indice perturb : ' ,i)\n",
    "        indices_Of_Pert_Images.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acc after perturbation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Lambda\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, MaxPool2D \n",
    "from keras.layers import Lambda\n",
    "import time\n",
    "from keras.utils.np_utils import to_categorical \n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input, decode_predictions\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "max_acc=0\n",
    "k=0\n",
    "for i in range ( len (x_test)):\n",
    "    max_acc=0\n",
    "    top_predicted=0\n",
    "    for each_model in arrays_of_VGG_Caus:\n",
    "        # Use the model to classify the digit\n",
    "        probs = each_model.predict (x_test[np.newaxis, i])\n",
    "        prediction = probs.argmax (axis=1)\n",
    "        probOrig = probs.max ()\n",
    "        orig_acc = probOrig\n",
    "        print ('pred[0]', prediction[0])\n",
    "        print('origin acc', orig_acc)\n",
    "        print (\"[INFO] Predicted: {}, Actual: {}\".format (\n",
    "        prediction[0], np.argmax (y_test[i])))\n",
    "        if orig_acc>max_acc:\n",
    "            top_predicted=prediction[0]\n",
    "#         K.clear_session ()    \n",
    "    print('----------------------------------------')        \n",
    "#     print('all models verified and top predicted is', top_predicted)\n",
    "    if top_predicted== np.argmax (y_test[i]):\n",
    "          print('image number', i)\n",
    "          k+=1\n",
    "          print('correctly classified:', k)\n",
    "          print('current accuracy:', k/len(x_test))\n",
    "    print('----------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
